// backend/hash/migrate_invoices_only.go
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// MIGRATION CIBLÃ‰E - Corrige les hashes des FACTURES et AVOIRS uniquement
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// Ce script NE TOUCHE PAS aux tickets POS (is_pos_ticket = true)
// Ã€ exÃ©cuter aprÃ¨s avoir constatÃ© des anomalies sur la chaÃ®ne FAC-*/AVO-*
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

package hash

import (
	"fmt"
	"log"
	"sort"

	"github.com/pocketbase/dbx"
	"github.com/pocketbase/pocketbase"
	"github.com/pocketbase/pocketbase/daos"
	"github.com/pocketbase/pocketbase/models"
)

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// STRUCTURES
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// MigrationStats contient les statistiques de migration
type MigrationStats struct {
	TotalScanned   int
	HashMismatches int
	ChainBroken    int
	Updated        int
	Errors         int
	SkippedTickets int
}

// DocumentAnomaly dÃ©crit une anomalie dÃ©tectÃ©e
type DocumentAnomaly struct {
	Number           string
	SequenceNumber   int
	InvoiceType      string
	HashMismatch     bool
	ChainBroken      bool
	ExpectedPrevHash string
	ActualPrevHash   string
	ExpectedHash     string
	ActualHash       string
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// 1. DIAGNOSTIC - Analyse les anomalies SANS modifier
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// DiagnoseInvoicesChain analyse la chaÃ®ne des factures/avoirs et liste les anomalies
// Ne modifie rien, retourne un rapport dÃ©taillÃ©
func DiagnoseInvoicesChain(app *pocketbase.PocketBase) ([]DocumentAnomaly, MigrationStats, error) {
	log.Println("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
	log.Println("ğŸ” DIAGNOSTIC: Analyse de la chaÃ®ne FACTURES/AVOIRS")
	log.Println("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")

	dao := app.Dao()
	var anomalies []DocumentAnomaly
	stats := MigrationStats{}

	// RÃ©cupÃ©rer UNIQUEMENT les factures et avoirs (pas les tickets POS)
	// is_pos_ticket = false OU is_pos_ticket est NULL (anciennes donnÃ©es)
	records, err := dao.FindRecordsByExpr("invoices",
		dbx.NewExp("sequence_number > 0 AND (is_pos_ticket = false OR is_pos_ticket IS NULL)"),
	)
	if err != nil {
		return nil, stats, fmt.Errorf("erreur chargement factures: %w", err)
	}

	// Trier par sequence_number
	sort.Slice(records, func(i, j int) bool {
		return records[i].GetInt("sequence_number") < records[j].GetInt("sequence_number")
	})

	// Compter les tickets ignorÃ©s
	allRecords, _ := dao.FindRecordsByExpr("invoices",
		dbx.NewExp("sequence_number > 0"),
	)
	stats.SkippedTickets = len(allRecords) - len(records)
	stats.TotalScanned = len(records)

	log.Printf("ğŸ“‹ %d facture(s)/avoir(s) Ã  analyser", len(records))
	log.Printf("â­ï¸  %d ticket(s) POS ignorÃ©(s)", stats.SkippedTickets)

	if len(records) == 0 {
		log.Println("âœ… Aucune facture/avoir Ã  analyser")
		return anomalies, stats, nil
	}

	// Grouper par owner_company
	byCompany := make(map[string][]*models.Record)
	for _, r := range records {
		company := r.GetString("owner_company")
		byCompany[company] = append(byCompany[company], r)
	}

	for company, docs := range byCompany {
		log.Printf("\nğŸ¢ Company: %s (%d documents)", company, len(docs))

		// Trier par sequence_number croissant
		sort.Slice(docs, func(i, j int) bool {
			return docs[i].GetInt("sequence_number") < docs[j].GetInt("sequence_number")
		})

		// Analyser chaque document
		for i, doc := range docs {
			seq := doc.GetInt("sequence_number")
			number := doc.GetString("number")
			invoiceType := doc.GetString("invoice_type")
			currentHash := doc.GetString("hash")
			currentPrevHash := doc.GetString("previous_hash")

			// Calculer le previous_hash attendu
			var expectedPrevHash string
			if i == 0 {
				// Premier document de cette company dans notre liste
				// VÃ©rifier s'il y a un document prÃ©cÃ©dent (seq-1)
				if seq == 1 {
					expectedPrevHash = GENESIS_HASH
				} else {
					// Chercher le document prÃ©cÃ©dent
					prevDoc := findPreviousDocumentBySeq(dao, company, seq, false)
					if prevDoc != nil {
						expectedPrevHash = prevDoc.GetString("hash")
					} else {
						expectedPrevHash = GENESIS_HASH
					}
				}
			} else {
				// Document prÃ©cÃ©dent dans notre liste triÃ©e
				expectedPrevHash = docs[i-1].GetString("hash")
			}

			// Calculer le hash attendu (avec le previous_hash corrigÃ© si nÃ©cessaire)
			// On simule ce que serait le hash si previous_hash Ã©tait correct
			tempDoc := doc
			if currentPrevHash != expectedPrevHash {
				// CrÃ©er une copie pour calculer le hash attendu
				tempDoc = cloneRecordForHashCalc(doc)
				tempDoc.Set("previous_hash", expectedPrevHash)
			}
			expectedHash := ComputeDocumentHash(tempDoc)

			// DÃ©tecter les anomalies
			hashMismatch := currentHash != expectedHash
			chainBroken := currentPrevHash != expectedPrevHash

			if hashMismatch || chainBroken {
				anomaly := DocumentAnomaly{
					Number:           number,
					SequenceNumber:   seq,
					InvoiceType:      invoiceType,
					HashMismatch:     hashMismatch,
					ChainBroken:      chainBroken,
					ExpectedPrevHash: expectedPrevHash,
					ActualPrevHash:   currentPrevHash,
					ExpectedHash:     expectedHash,
					ActualHash:       currentHash,
				}
				anomalies = append(anomalies, anomaly)

				if hashMismatch {
					stats.HashMismatches++
				}
				if chainBroken {
					stats.ChainBroken++
				}

				// Log dÃ©taillÃ©
				log.Printf("   âŒ %s (seq=%d, type=%s):", number, seq, invoiceType)
				if chainBroken {
					log.Printf("      ğŸ”— previous_hash: %s... â†’ attendu: %s...",
						truncateHash(currentPrevHash), truncateHash(expectedPrevHash))
				}
				if hashMismatch {
					log.Printf("      #ï¸âƒ£ hash: %s... â†’ attendu: %s...",
						truncateHash(currentHash), truncateHash(expectedHash))
				}
			}
		}
	}

	// RÃ©sumÃ©
	log.Println("\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
	log.Printf("ğŸ“Š RÃ‰SUMÃ‰ DIAGNOSTIC:")
	log.Printf("   â€¢ Documents analysÃ©s: %d", stats.TotalScanned)
	log.Printf("   â€¢ Tickets ignorÃ©s: %d", stats.SkippedTickets)
	log.Printf("   â€¢ Anomalies hash: %d", stats.HashMismatches)
	log.Printf("   â€¢ ChaÃ®nes brisÃ©es: %d", stats.ChainBroken)
	log.Printf("   â€¢ Total anomalies: %d", len(anomalies))
	log.Println("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")

	return anomalies, stats, nil
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// 2. MIGRATION - Corrige les hashes (avec option dry-run)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// MigrateInvoicesHashes corrige les hashes des factures et avoirs
// Si dryRun=true, affiche ce qui serait fait sans modifier
func MigrateInvoicesHashes(app *pocketbase.PocketBase, dryRun bool) (MigrationStats, error) {
	mode := "MIGRATION"
	if dryRun {
		mode = "DRY-RUN (simulation)"
	}

	log.Println("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
	log.Printf("ğŸ”§ %s: Correction des hashes FACTURES/AVOIRS", mode)
	log.Println("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")

	dao := app.Dao()
	stats := MigrationStats{}

	// RÃ©cupÃ©rer UNIQUEMENT les factures et avoirs
	records, err := dao.FindRecordsByExpr("invoices",
		dbx.NewExp("sequence_number > 0 AND (is_pos_ticket = false OR is_pos_ticket IS NULL)"),
	)
	if err != nil {
		return stats, fmt.Errorf("erreur chargement factures: %w", err)
	}

	// Trier par sequence_number
	sort.Slice(records, func(i, j int) bool {
		return records[i].GetInt("sequence_number") < records[j].GetInt("sequence_number")
	})

	stats.TotalScanned = len(records)
	log.Printf("ğŸ“‹ %d facture(s)/avoir(s) Ã  traiter", len(records))

	if len(records) == 0 {
		log.Println("âœ… Aucune facture/avoir Ã  migrer")
		return stats, nil
	}

	// Grouper par owner_company
	byCompany := make(map[string][]*models.Record)
	for _, r := range records {
		company := r.GetString("owner_company")
		byCompany[company] = append(byCompany[company], r)
	}

	for company, docs := range byCompany {
		log.Printf("\nğŸ¢ Company: %s (%d documents)", company, len(docs))

		// Trier par sequence_number croissant (CRUCIAL pour le chaÃ®nage)
		sort.Slice(docs, func(i, j int) bool {
			return docs[i].GetInt("sequence_number") < docs[j].GetInt("sequence_number")
		})

		// Traiter chaque document dans l'ordre
		for i, doc := range docs {
			seq := doc.GetInt("sequence_number")
			number := doc.GetString("number")
			oldHash := doc.GetString("hash")
			oldPrevHash := doc.GetString("previous_hash")

			// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
			// Ã‰TAPE 1: DÃ©terminer le previous_hash correct
			// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
			var expectedPrevHash string

			if i == 0 {
				// Premier document de cette company
				if seq == 1 {
					expectedPrevHash = GENESIS_HASH
				} else {
					// Il y a peut-Ãªtre des tickets avant ce document
					// Chercher le dernier document (tous types) avec seq < current seq
					prevDoc := findPreviousDocumentBySeq(dao, company, seq, true) // true = inclure tickets
					if prevDoc != nil {
						expectedPrevHash = prevDoc.GetString("hash")
					} else {
						expectedPrevHash = GENESIS_HASH
					}
				}
			} else {
				// Le document prÃ©cÃ©dent dans NOTRE liste (factures/avoirs uniquement)
				// Mais attention: il peut y avoir des tickets entre les deux!
				prevSeq := docs[i-1].GetInt("sequence_number")

				if seq == prevSeq+1 {
					// SÃ©quence continue â†’ le previous est le doc prÃ©cÃ©dent
					expectedPrevHash = docs[i-1].GetString("hash")
				} else {
					// Il y a un "trou" â†’ chercher le vrai prÃ©cÃ©dent (peut Ãªtre un ticket)
					prevDoc := findPreviousDocumentBySeq(dao, company, seq, true)
					if prevDoc != nil {
						expectedPrevHash = prevDoc.GetString("hash")
					} else {
						expectedPrevHash = docs[i-1].GetString("hash")
					}
				}
			}

			// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
			// Ã‰TAPE 2: Corriger previous_hash si nÃ©cessaire
			// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
			prevHashChanged := false
			if oldPrevHash != expectedPrevHash {
				prevHashChanged = true
				if !dryRun {
					doc.Set("previous_hash", expectedPrevHash)
				}
				log.Printf("   ğŸ”— %s (seq=%d): previous_hash corrigÃ©", number, seq)
				log.Printf("      %s... â†’ %s...", truncateHash(oldPrevHash), truncateHash(expectedPrevHash))
			}

			// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
			// Ã‰TAPE 3: Recalculer le hash
			// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
			var newHash string
			if dryRun && prevHashChanged {
				// En dry-run, simuler avec le previous_hash corrigÃ©
				tempDoc := cloneRecordForHashCalc(doc)
				tempDoc.Set("previous_hash", expectedPrevHash)
				newHash = ComputeDocumentHash(tempDoc)
			} else {
				newHash = ComputeDocumentHash(doc)
			}

			hashChanged := oldHash != newHash
			if hashChanged {
				if !dryRun {
					doc.Set("hash", newHash)
				}
				log.Printf("   ğŸ”„ %s (seq=%d): hash recalculÃ©", number, seq)
				log.Printf("      %s... â†’ %s...", truncateHash(oldHash), truncateHash(newHash))
			}

			// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
			// Ã‰TAPE 4: Sauvegarder si modifiÃ©
			// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
			if prevHashChanged || hashChanged {
				if !dryRun {
					if err := dao.SaveRecord(doc); err != nil {
						log.Printf("   âŒ Erreur sauvegarde %s: %v", number, err)
						stats.Errors++
					} else {
						stats.Updated++
					}
				} else {
					stats.Updated++ // En dry-run, compter ce qui SERAIT mis Ã  jour
				}
			}
		}
	}

	// RÃ©sumÃ©
	log.Println("\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
	if dryRun {
		log.Printf("ğŸ“Š RÃ‰SUMÃ‰ DRY-RUN (aucune modification effectuÃ©e):")
		log.Printf("   â€¢ Documents analysÃ©s: %d", stats.TotalScanned)
		log.Printf("   â€¢ SERAIENT mis Ã  jour: %d", stats.Updated)
	} else {
		log.Printf("ğŸ“Š RÃ‰SUMÃ‰ MIGRATION:")
		log.Printf("   â€¢ Documents analysÃ©s: %d", stats.TotalScanned)
		log.Printf("   â€¢ Mis Ã  jour: %d", stats.Updated)
		log.Printf("   â€¢ Erreurs: %d", stats.Errors)
	}
	log.Println("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")

	return stats, nil
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// 3. VÃ‰RIFICATION POST-MIGRATION
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// VerifyInvoicesChain vÃ©rifie l'intÃ©gritÃ© de la chaÃ®ne aprÃ¨s migration
func VerifyInvoicesChain(app *pocketbase.PocketBase) error {
	log.Println("\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
	log.Println("ğŸ” VÃ‰RIFICATION POST-MIGRATION: ChaÃ®ne FACTURES/AVOIRS")
	log.Println("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")

	anomalies, stats, err := DiagnoseInvoicesChain(app)
	if err != nil {
		return err
	}

	if len(anomalies) == 0 {
		log.Println("\nâœ… SUCCÃˆS: Toute la chaÃ®ne des factures/avoirs est intÃ¨gre!")
		return nil
	}

	log.Printf("\nâš ï¸ ATTENTION: %d anomalie(s) dÃ©tectÃ©e(s) aprÃ¨s migration", len(anomalies))
	log.Printf("   â€¢ Hash incorrects: %d", stats.HashMismatches)
	log.Printf("   â€¢ ChaÃ®nes brisÃ©es: %d", stats.ChainBroken)

	return fmt.Errorf("%d anomalies restantes", len(anomalies))
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// FONCTIONS UTILITAIRES (noms uniques pour Ã©viter les conflits avec migrate.go)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// findPreviousDocumentBySeq trouve le document avec sequence_number = seq-1
// Si includeTickets=true, cherche dans TOUS les documents
// Si includeTickets=false, cherche uniquement dans les factures/avoirs
func findPreviousDocumentBySeq(dao *daos.Dao, company string, seq int, includeTickets bool) *models.Record {
	var expr dbx.Expression
	if includeTickets {
		expr = dbx.NewExp("owner_company = {:company} AND sequence_number = {:seq}",
			dbx.Params{"company": company, "seq": seq - 1})
	} else {
		expr = dbx.NewExp("owner_company = {:company} AND sequence_number = {:seq} AND (is_pos_ticket = false OR is_pos_ticket IS NULL)",
			dbx.Params{"company": company, "seq": seq - 1})
	}

	records, err := dao.FindRecordsByExpr("invoices", expr)
	if err != nil || len(records) == 0 {
		return nil
	}
	return records[0]
}

// cloneRecordForHashCalc crÃ©e une copie superficielle du record pour calculer un hash
// sans modifier l'original
func cloneRecordForHashCalc(original *models.Record) *models.Record {
	clone := &models.Record{}
	*clone = *original
	return clone
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// FONCTION PRINCIPALE D'EXÃ‰CUTION
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// RunFullChainMigration recalcule TOUTE la chaÃ®ne de documents
// Factures + Tickets + Avoirs - TOUT d'un coup dans l'ordre
func RunFullChainMigration(app *pocketbase.PocketBase) error {
	log.Println("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
	log.Println("ğŸ”§ MIGRATION COMPLÃˆTE: Recalcul de TOUTE la chaÃ®ne")
	log.Println("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")

	dao := app.Dao()

	// RÃ©cupÃ©rer TOUS les documents avec un sequence_number
	records, err := dao.FindRecordsByExpr("invoices",
		dbx.NewExp("sequence_number > 0"),
	)
	if err != nil {
		return fmt.Errorf("erreur chargement documents: %w", err)
	}

	log.Printf("ğŸ“‹ %d document(s) Ã  traiter", len(records))

	if len(records) == 0 {
		log.Println("âœ… Aucun document Ã  migrer")
		return nil
	}

	// Grouper par owner_company
	byCompany := make(map[string][]*models.Record)
	for _, r := range records {
		company := r.GetString("owner_company")
		byCompany[company] = append(byCompany[company], r)
	}

	totalUpdated := 0
	totalErrors := 0

	for company, docs := range byCompany {
		log.Printf("\nğŸ¢ Company: %s (%d documents)", company, len(docs))

		// Trier par sequence_number croissant
		sort.Slice(docs, func(i, j int) bool {
			return docs[i].GetInt("sequence_number") < docs[j].GetInt("sequence_number")
		})

		// Recalculer les hashes dans l'ordre
		for i, doc := range docs {
			seq := doc.GetInt("sequence_number")
			number := doc.GetString("number")
			oldHash := doc.GetString("hash")
			oldPrevHash := doc.GetString("previous_hash")

			// DÃ©terminer le previous_hash correct
			var expectedPrevHash string
			if seq == 1 {
				expectedPrevHash = GENESIS_HASH
			} else if i > 0 && docs[i-1].GetInt("sequence_number") == seq-1 {
				// Le document prÃ©cÃ©dent est dans notre liste
				expectedPrevHash = docs[i-1].GetString("hash")
			} else {
				// Chercher le document prÃ©cÃ©dent dans la DB
				prevRecords, _ := dao.FindRecordsByExpr("invoices",
					dbx.NewExp("owner_company = {:company} AND sequence_number = {:seq}",
						dbx.Params{"company": company, "seq": seq - 1}),
				)
				if len(prevRecords) > 0 {
					expectedPrevHash = prevRecords[0].GetString("hash")
				} else {
					expectedPrevHash = GENESIS_HASH
				}
			}

			// Corriger previous_hash si nÃ©cessaire
			prevHashChanged := oldPrevHash != expectedPrevHash
			if prevHashChanged {
				doc.Set("previous_hash", expectedPrevHash)
			}

			// Recalculer le hash
			newHash := ComputeDocumentHash(doc)
			hashChanged := oldHash != newHash
			if hashChanged {
				doc.Set("hash", newHash)
			}

			// Sauvegarder si modifiÃ©
			if prevHashChanged || hashChanged {
				log.Printf("   ğŸ”„ %s (seq=%d)", number, seq)
				if err := dao.SaveRecord(doc); err != nil {
					log.Printf("   âŒ Erreur: %v", err)
					totalErrors++
				} else {
					totalUpdated++
				}
			}
		}
	}

	log.Println("\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
	log.Printf("âœ… MIGRATION TERMINÃ‰E: %d document(s) corrigÃ©(s), %d erreur(s)", totalUpdated, totalErrors)
	log.Println("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")

	return nil
}

// FixSingleTicket corrige le hash d'un ticket spÃ©cifique (ex: TIK-2026-000001)
// Appel: hash.FixSingleTicket(pb, "TIK-2026-000001")
func FixSingleTicket(app *pocketbase.PocketBase, ticketNumber string) error {
	log.Printf("ğŸ”§ Correction du ticket: %s", ticketNumber)
	dao := app.Dao()

	// 1. Trouver le ticket
	records, err := dao.FindRecordsByExpr("invoices",
		dbx.NewExp("number = {:num}", dbx.Params{"num": ticketNumber}),
	)
	if err != nil || len(records) == 0 {
		return fmt.Errorf("ticket %s introuvable", ticketNumber)
	}
	ticket := records[0]

	seq := ticket.GetInt("sequence_number")
	company := ticket.GetString("owner_company")
	oldHash := ticket.GetString("hash")
	oldPrevHash := ticket.GetString("previous_hash")

	log.Printf("   Ticket trouvÃ©: seq=%d, company=%s", seq, company)
	log.Printf("   Hash actuel: %s...", truncateHash(oldHash))
	log.Printf("   PrevHash actuel: %s...", truncateHash(oldPrevHash))

	// 2. Trouver le document prÃ©cÃ©dent (sequence_number - 1)
	var expectedPrevHash string
	if seq == 1 {
		expectedPrevHash = GENESIS_HASH
	} else {
		prevRecords, err := dao.FindRecordsByExpr("invoices",
			dbx.NewExp("owner_company = {:company} AND sequence_number = {:seq}",
				dbx.Params{"company": company, "seq": seq - 1}),
		)
		if err != nil || len(prevRecords) == 0 {
			log.Printf("   âš ï¸ Document prÃ©cÃ©dent (seq=%d) introuvable, utilisation GENESIS_HASH", seq-1)
			expectedPrevHash = GENESIS_HASH
		} else {
			expectedPrevHash = prevRecords[0].GetString("hash")
			log.Printf("   Document prÃ©cÃ©dent trouvÃ©: %s (seq=%d)",
				prevRecords[0].GetString("number"), seq-1)
		}
	}

	log.Printf("   PrevHash attendu: %s...", truncateHash(expectedPrevHash))

	// 3. Corriger previous_hash si nÃ©cessaire
	if oldPrevHash != expectedPrevHash {
		ticket.Set("previous_hash", expectedPrevHash)
		log.Printf("   ğŸ”— previous_hash corrigÃ©")
	}

	// 4. Recalculer le hash
	newHash := ComputeDocumentHash(ticket)
	log.Printf("   Hash recalculÃ©: %s...", truncateHash(newHash))

	if oldHash != newHash {
		ticket.Set("hash", newHash)
		log.Printf("   ğŸ”„ hash mis Ã  jour")
	}

	// 5. Sauvegarder
	if err := dao.SaveRecord(ticket); err != nil {
		return fmt.Errorf("erreur sauvegarde: %w", err)
	}

	log.Printf("âœ… Ticket %s corrigÃ© avec succÃ¨s!", ticketNumber)
	return nil
}

// RunTicketsMigration recalcule TOUTE la chaÃ®ne des tickets POS
// C'est la fonction Ã  appeler pour corriger tous les tickets d'un coup
func RunTicketsMigration(app *pocketbase.PocketBase, dryRun bool) error {
	mode := "MIGRATION"
	if dryRun {
		mode = "DRY-RUN"
	}

	log.Println("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
	log.Printf("ğŸ« %s: Recalcul chaÃ®ne TICKETS POS", mode)
	log.Println("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")

	dao := app.Dao()

	// RÃ©cupÃ©rer TOUS les tickets POS
	records, err := dao.FindRecordsByExpr("invoices",
		dbx.NewExp("sequence_number > 0 AND is_pos_ticket = true"),
	)
	if err != nil {
		return fmt.Errorf("erreur chargement tickets: %w", err)
	}

	log.Printf("ğŸ“‹ %d ticket(s) POS Ã  traiter", len(records))

	if len(records) == 0 {
		log.Println("âœ… Aucun ticket Ã  migrer")
		return nil
	}

	// Trier par sequence_number
	sort.Slice(records, func(i, j int) bool {
		return records[i].GetInt("sequence_number") < records[j].GetInt("sequence_number")
	})

	// Grouper par owner_company
	byCompany := make(map[string][]*models.Record)
	for _, r := range records {
		company := r.GetString("owner_company")
		byCompany[company] = append(byCompany[company], r)
	}

	totalUpdated := 0
	totalErrors := 0

	for company, tickets := range byCompany {
		log.Printf("\nğŸ¢ Company: %s (%d tickets)", company, len(tickets))

		// Trier par sequence_number
		sort.Slice(tickets, func(i, j int) bool {
			return tickets[i].GetInt("sequence_number") < tickets[j].GetInt("sequence_number")
		})

		for i, ticket := range tickets {
			seq := ticket.GetInt("sequence_number")
			number := ticket.GetString("number")
			oldHash := ticket.GetString("hash")
			oldPrevHash := ticket.GetString("previous_hash")

			// DÃ©terminer le previous_hash correct
			var expectedPrevHash string
			if i == 0 {
				// Premier ticket de cette company
				if seq == 1 {
					expectedPrevHash = GENESIS_HASH
				} else {
					// Chercher le document prÃ©cÃ©dent (tous types)
					prevRecords, _ := dao.FindRecordsByExpr("invoices",
						dbx.NewExp("owner_company = {:company} AND sequence_number = {:seq}",
							dbx.Params{"company": company, "seq": seq - 1}),
					)
					if len(prevRecords) > 0 {
						expectedPrevHash = prevRecords[0].GetString("hash")
					} else {
						expectedPrevHash = GENESIS_HASH
					}
				}
			} else {
				// Le ticket prÃ©cÃ©dent dans notre liste
				prevSeq := tickets[i-1].GetInt("sequence_number")
				if seq == prevSeq+1 {
					expectedPrevHash = tickets[i-1].GetString("hash")
				} else {
					// Trou dans la sÃ©quence - chercher le vrai prÃ©cÃ©dent
					prevRecords, _ := dao.FindRecordsByExpr("invoices",
						dbx.NewExp("owner_company = {:company} AND sequence_number = {:seq}",
							dbx.Params{"company": company, "seq": seq - 1}),
					)
					if len(prevRecords) > 0 {
						expectedPrevHash = prevRecords[0].GetString("hash")
					} else {
						expectedPrevHash = tickets[i-1].GetString("hash")
					}
				}
			}

			// Corriger previous_hash si nÃ©cessaire
			prevHashChanged := false
			if oldPrevHash != expectedPrevHash {
				prevHashChanged = true
				if !dryRun {
					ticket.Set("previous_hash", expectedPrevHash)
				}
			}

			// Recalculer le hash
			var newHash string
			if dryRun && prevHashChanged {
				tempDoc := &models.Record{}
				*tempDoc = *ticket
				tempDoc.Set("previous_hash", expectedPrevHash)
				newHash = ComputeDocumentHash(tempDoc)
			} else {
				newHash = ComputeDocumentHash(ticket)
			}

			hashChanged := oldHash != newHash
			if hashChanged && !dryRun {
				ticket.Set("hash", newHash)
			}

			// Sauvegarder si modifiÃ©
			if prevHashChanged || hashChanged {
				log.Printf("   ğŸ”„ %s (seq=%d): corrigÃ©", number, seq)
				if !dryRun {
					if err := dao.SaveRecord(ticket); err != nil {
						log.Printf("   âŒ Erreur: %v", err)
						totalErrors++
					} else {
						totalUpdated++
					}
				} else {
					totalUpdated++
				}
			}
		}
	}

	log.Println("\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
	if dryRun {
		log.Printf("ğŸ“Š DRY-RUN: %d ticket(s) SERAIENT corrigÃ©(s)", totalUpdated)
	} else {
		log.Printf("âœ… MIGRATION: %d ticket(s) corrigÃ©(s), %d erreur(s)", totalUpdated, totalErrors)
	}
	log.Println("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")

	return nil
}

// RunInvoicesMigration exÃ©cute la migration complÃ¨te avec diagnostic et vÃ©rification
// C'est la fonction Ã  appeler depuis main.go ou une route admin
func RunInvoicesMigration(app *pocketbase.PocketBase, dryRun bool) error {
	log.Println("")
	log.Println("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
	log.Println("â•‘   MIGRATION HASHES FACTURES/AVOIRS - NF525 COMPLIANT          â•‘")
	log.Println("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
	log.Println("")

	// Ã‰tape 1: Diagnostic initial
	log.Println("ğŸ“Œ Ã‰TAPE 1/3: Diagnostic initial")
	anomalies, _, err := DiagnoseInvoicesChain(app)
	if err != nil {
		return fmt.Errorf("erreur diagnostic: %w", err)
	}

	if len(anomalies) == 0 {
		log.Println("\nâœ… Aucune anomalie dÃ©tectÃ©e. Migration non nÃ©cessaire.")
		return nil
	}

	// Ã‰tape 2: Migration
	log.Println("\nğŸ“Œ Ã‰TAPE 2/3: Migration")
	stats, err := MigrateInvoicesHashes(app, dryRun)
	if err != nil {
		return fmt.Errorf("erreur migration: %w", err)
	}

	if dryRun {
		log.Println("\nâš ï¸ MODE DRY-RUN: Aucune modification effectuÃ©e.")
		log.Println("   Relancez avec dryRun=false pour appliquer les corrections.")
		return nil
	}

	// Ã‰tape 3: VÃ©rification post-migration
	log.Println("\nğŸ“Œ Ã‰TAPE 3/3: VÃ©rification post-migration")
	if err := VerifyInvoicesChain(app); err != nil {
		return err
	}

	log.Println("")
	log.Println("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
	log.Printf("â•‘   âœ… MIGRATION TERMINÃ‰E: %d document(s) corrigÃ©(s)            â•‘", stats.Updated)
	log.Println("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
	log.Println("")

	return nil
}
